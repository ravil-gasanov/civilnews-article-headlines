{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "word2vec-xgbregressor.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Quick & dirty prototype to evaluate what the data can potentially yield"
      ],
      "metadata": {
        "id": "t-GU6_TQ-sQ_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "6YTKPa7qMA2V"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import regex\n",
        "import io\n",
        "import math\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('train.csv')"
      ],
      "metadata": {
        "id": "ikSsNhWOMer5"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "headlines = train['headline'].copy()"
      ],
      "metadata": {
        "id": "xfeS7FdkMni6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cleaning"
      ],
      "metadata": {
        "id": "2r71YlURNcsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "en_stop_words = stopwords.words('english')\n",
        "print(en_stop_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nO_4KzziObZa",
        "outputId": "9e4ba40d-6f7c-4d3f-dd61-ecc38e0d17a2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def headline_to_clean_words(headline):\n",
        "  headline = headline.lower()\n",
        "  words = regex.findall(r'\\w+', headline)\n",
        "  clean_words = []\n",
        "  \n",
        "  # what is a more idiomatic / efficient way to do this?\n",
        "  for word in words:\n",
        "    if word not in en_stop_words:\n",
        "      clean_words.append(word)\n",
        "\n",
        "\n",
        "  return clean_words"
      ],
      "metadata": {
        "id": "3Dj_GOdSO_vz"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_headlines = headlines.apply(headline_to_clean_words)"
      ],
      "metadata": {
        "id": "necTmIzQP1St"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_headlines"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWrA5mrTP4pH",
        "outputId": "fb02d666-c3f5-41b0-e04c-54ce2e9b2630"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        [medvedev, signs, cooperation, treaties, sokhu...\n",
              "1                    [local, self, governance, governance]\n",
              "2        [secretary, general, council, europe, meets, g...\n",
              "3                          [faction, revival, trust, ngos]\n",
              "4              [osce, urges, russia, leave, gudauta, base]\n",
              "                               ...                        \n",
              "24406          [eu, georgia, conclude, free, trade, talks]\n",
              "24407    [georgian, patriarch, visits, moscow, kiev, mi...\n",
              "24408            [change, party, funding, rules, proposed]\n",
              "24409                  [georgia, 1h, 2013, foreign, trade]\n",
              "24410    [govt, gets, advice, handle, illegal, surveill...\n",
              "Name: headline, Length: 24411, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building the vocabulary word_context pairs"
      ],
      "metadata": {
        "id": "6-p-WsUzUVTr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = clean_headlines.explode().unique()\n",
        "vocab_len = len(vocab)"
      ],
      "metadata": {
        "id": "okwmQUaURXbs"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_to_idx = {word:idx for (idx, word) in enumerate(vocab)}"
      ],
      "metadata": {
        "id": "z8adqcSRTlfd"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot_encode(word_idx):\n",
        "  ohe = torch.zeros((vocab_len, 1), dtype = torch.float)\n",
        "  ohe[word_idx] = 1\n",
        "\n",
        "  return ohe"
      ],
      "metadata": {
        "id": "1-3HGOvIVUve"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_word_context_pairs(words):\n",
        "  word_context_pairs = []\n",
        "  for i in range(0, len(words) - 1):\n",
        "    for j in range(i + 1, len(words)):\n",
        "      if i != j:\n",
        "        word = word_to_idx[words[i]]\n",
        "        context = word_to_idx[words[j]]\n",
        "        word_context_pairs.append((word, context))\n",
        "        word_context_pairs.append((context, word))\n",
        "        \n",
        "  return word_context_pairs"
      ],
      "metadata": {
        "id": "J6O5Z4JWWNuV"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_context_pairs = clean_headlines.apply(get_word_context_pairs).explode().dropna().reset_index(drop = True)"
      ],
      "metadata": {
        "id": "QS9JkEveWTh7"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_context_pairs.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-t_NTWekykh",
        "outputId": "d2aac9c3-9cdb-4f5c-a4f9-db8443bb6058"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    (0, 1)\n",
              "1    (1, 0)\n",
              "2    (0, 2)\n",
              "3    (2, 0)\n",
              "4    (0, 3)\n",
              "Name: headline, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Word2Vec"
      ],
      "metadata": {
        "id": "usalXGqge12o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Word2Vec(nn.Module):\n",
        "  EMBED_DIM = 300\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    self.fc1 = nn.Linear(vocab_len, self.EMBED_DIM)\n",
        "    self.fc2 = nn.Linear(self.EMBED_DIM, vocab_len)\n",
        "    \n",
        "    initrange = 0.5\n",
        "    self.fc1.weight.data.uniform_(-initrange, initrange)\n",
        "    self.fc2.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    \n",
        "  def forward(self, X):\n",
        "    X = X.view(-1, vocab_len)\n",
        "\n",
        "    emb = self.fc1(X)\n",
        "    X = self.fc2(emb)\n",
        "    X = F.log_softmax(X, dim = 1)\n",
        "    return X, emb"
      ],
      "metadata": {
        "id": "sxM5mdVieTOg"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.notebook import tqdm\n",
        "\n",
        "class Trainer:\n",
        "  def __init__(self, model):\n",
        "    self.model = model\n",
        "    self.model.to(device)\n",
        "\n",
        "    self.learning_rate = 0.05\n",
        "    self.epochs = 100\n",
        "\n",
        "    self.optimizer = optim.SGD(self.model.parameters(), self.learning_rate, momentum=0.9)\n",
        "    self.criterion =  nn.NLLLoss()\n",
        "    self.dataloader = DataLoader(word_context_pairs, batch_size = 64, collate_fn = self.collate_fn, shuffle=True)\n",
        "\n",
        "  def collate_fn(self, word_context_pairs):\n",
        "      words, contexts = [], []\n",
        "      try:\n",
        "        for word, context in word_context_pairs:\n",
        "          word = one_hot_encode(word)\n",
        "          #context = one_hot_encode(context).squeeze().type(torch.long)\n",
        "          context = torch.tensor(context)\n",
        "          words.append(word)\n",
        "          contexts.append(context)\n",
        "      except:\n",
        "        print(word_context_pairs)\n",
        "      \n",
        "      return torch.stack(words), torch.stack(contexts)\n",
        "  \n",
        "  def train(self):\n",
        "    self.model.train()\n",
        "    print(\"Training started\")\n",
        "    for epoch in range(self.epochs):\n",
        "      for words, contexts in tqdm(self.dataloader):\n",
        "        self.optimizer.zero_grad()\n",
        "\n",
        "        pred_contexts, embs = self.model(words.to(device))\n",
        "        pred_contexts = pred_contexts.squeeze()\n",
        "\n",
        "        loss = self.criterion(pred_contexts.to(device), contexts.to(device))\n",
        "\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "    print(\"Training finished\")"
      ],
      "metadata": {
        "id": "VCq2N7Bphu91"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Word2Vec().to(device)\n",
        "model.load_state_dict(torch.load('civilnews-train-word2vec-2022-08-05.pt'))\n",
        "#trainer = Trainer(model)"
      ],
      "metadata": {
        "id": "oywcAWYpjZ_e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "034c655e-cc7b-4145-e6bb-00902b8850d8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#trainer.train()"
      ],
      "metadata": {
        "id": "3s2hYN-Zjg1N"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#torch.save(trainer.model.state_dict(), 'civilnews_word2vec.pt')"
      ],
      "metadata": {
        "id": "UWgpESOCtFsB"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predict views by Average embeds (Failed)"
      ],
      "metadata": {
        "id": "UjdZERGMD_L9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def headlines_to_average_embeddings(words):\n",
        "  embeds = []\n",
        "  for word in words:\n",
        "    word_idx = word_to_idx[word]\n",
        "    word = one_hot_encode(word_idx)\n",
        "    _, word_embed = model(word.to(device))\n",
        "    embeds.append(word_embed.detach().cpu().numpy())\n",
        "\n",
        "  return np.mean(embeds)"
      ],
      "metadata": {
        "id": "YJIaO-JO8USV"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "headlines_in_average_embeds = clean_headlines.apply(headlines_to_average_embeddings)"
      ],
      "metadata": {
        "id": "_kG5cZXS_NDg"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train) == len(headlines_in_average_embeds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxVTiwdfAWg0",
        "outputId": "65f2e0da-cd29-46cb-e714-b9779851a1ac"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "aev = pd.concat([pd.Series(headlines_in_average_embeds.values), train.views], axis = 1)\n",
        "#pd.DataFrame(, train.views)"
      ],
      "metadata": {
        "id": "PCFvq99AAf1n"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aev.columns = ['average_embeds', 'views']"
      ],
      "metadata": {
        "id": "FcEqvUOaB84T"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aev = pd.DataFrame(aev.iloc[pd.to_numeric(aev['views'], errors = 'coerce').dropna().index, :])\n",
        "aev['views'] = aev['views'].astype(float)"
      ],
      "metadata": {
        "id": "5cGQC0wDDjt6"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBRegressor\n",
        "from sklearn.linear_model import LinearRegression"
      ],
      "metadata": {
        "id": "udUTEp8Y28eb"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xgbr = XGBRegressor()"
      ],
      "metadata": {
        "id": "n2es9mVE3Fch"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = pd.DataFrame(aev['average_embeds']), aev['views']\n",
        "X = (X - X.mean()) / (X.max() - X.min())"
      ],
      "metadata": {
        "id": "Fv4o63nS3JCt"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_validate"
      ],
      "metadata": {
        "id": "j2bUlUL_7CFL"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cross_validate(xgbr, X, y, cv = 10, scoring = 'explained_variance')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5q3353ai7D2L",
        "outputId": "1bcc1b8e-cff3-4b13-f03b-c5adb009ac5a"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[07:03:41] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[07:03:42] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[07:03:42] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[07:03:43] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[07:03:43] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[07:03:43] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[07:03:44] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[07:03:44] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[07:03:44] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[07:03:45] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'fit_time': array([0.38888288, 0.38305426, 0.3848412 , 0.38515902, 0.37467551,\n",
              "        0.38218546, 0.3794167 , 0.37620234, 0.3965323 , 0.62152886]),\n",
              " 'score_time': array([0.00730467, 0.00822711, 0.00621939, 0.00681067, 0.00699878,\n",
              "        0.00656247, 0.00702333, 0.00717139, 0.00688028, 0.00898051]),\n",
              " 'test_score': array([-2.13370197e-03,  5.53929980e-04, -6.81335405e-04, -4.52953450e-03,\n",
              "        -5.15985303e-03, -2.80369640e-01, -2.47259007e+00, -5.16063092e+02,\n",
              "        -2.67436282e-02, -9.69880684e-05])}"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    }
  ]
}